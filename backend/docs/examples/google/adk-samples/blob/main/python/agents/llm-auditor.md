[Skip to content](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#start-of-content)
You signed in with another tab or window. [Reload](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor) to refresh your session. Dismiss alert
{{ message }}
[ google ](https://github.com/google) / **[adk-samples](https://github.com/google/adk-samples) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2Fgoogle%2Fadk-samples) You must be signed in to change notification settings
  * [ Fork 987 ](https://github.com/login?return_to=%2Fgoogle%2Fadk-samples)
  * [ Star  3.4k ](https://github.com/login?return_to=%2Fgoogle%2Fadk-samples)


## Collapse file tree
## Files
main
Search this repository
/
# llm-auditor
/
Copy path
## Directory actions
## More options
More options
## Directory actions
## More options
More options
## Latest commit
[![jackwotherspoon](https://avatars.githubusercontent.com/u/32113413?v=4&size=40)](https://github.com/jackwotherspoon)[jackwotherspoon](https://github.com/google/adk-samples/commits?author=jackwotherspoon)
[feat: update all models to GA versions (](https://github.com/google/adk-samples/commit/5969ecf647a93e0505588c6438895ccbbb2f9cae)[#187](https://github.com/google/adk-samples/pull/187)[)](https://github.com/google/adk-samples/commit/5969ecf647a93e0505588c6438895ccbbb2f9cae)
Jun 19, 2025
[5969ecf](https://github.com/google/adk-samples/commit/5969ecf647a93e0505588c6438895ccbbb2f9cae) Â· Jun 19, 2025
## History
[History](https://github.com/google/adk-samples/commits/main/python/agents/llm-auditor)
Open commit details
[](https://github.com/google/adk-samples/commits/main/python/agents/llm-auditor)
/
# llm-auditor
/
Top
## Folders and files
Name| Name| Last commit message| Last commit date
---|---|---|---
### parent directory
[..](https://github.com/google/adk-samples/tree/main/python/agents)
[deployment](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor/deployment "deployment")| [deployment](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor/deployment "deployment")| [Add python top-level directory](https://github.com/google/adk-samples/commit/adf640295027be408de52734372b0f8d53e01f75 "Add python top-level directory")| May 20, 2025
[eval](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor/eval "eval")| [eval](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor/eval "eval")| [Fixing eval & deploy in sample agents](https://github.com/google/adk-samples/commit/6683ea14afb60f2c4e71921a4fc501de1090ff33 "Fixing eval & deploy in sample agents
academic-research, brand-search-optimization, customer-service,
financial-advisor, llm-auditor")| May 23, 2025
[llm_auditor](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor/llm_auditor "llm_auditor")| [llm_auditor](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor/llm_auditor "llm_auditor")| [feat: update all models to GA versions (](https://github.com/google/adk-samples/commit/5969ecf647a93e0505588c6438895ccbbb2f9cae "feat: update all models to GA versions \(#187\)")[#187](https://github.com/google/adk-samples/pull/187)[)](https://github.com/google/adk-samples/commit/5969ecf647a93e0505588c6438895ccbbb2f9cae "feat: update all models to GA versions \(#187\)")| Jun 19, 2025
[tests](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor/tests "tests")| [tests](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor/tests "tests")| [Update llm-auditor to ADK 1.0](https://github.com/google/adk-samples/commit/6c187b0c436f5b629a5c4cc7dcbe9b03dd8d48c1 "Update llm-auditor to ADK 1.0")| May 22, 2025
[.env.example](https://github.com/google/adk-samples/blob/main/python/agents/llm-auditor/.env.example ".env.example")| [.env.example](https://github.com/google/adk-samples/blob/main/python/agents/llm-auditor/.env.example ".env.example")| [Add python top-level directory](https://github.com/google/adk-samples/commit/adf640295027be408de52734372b0f8d53e01f75 "Add python top-level directory")| May 20, 2025
[README.md](https://github.com/google/adk-samples/blob/main/python/agents/llm-auditor/README.md "README.md")| [README.md](https://github.com/google/adk-samples/blob/main/python/agents/llm-auditor/README.md "README.md")| [Update agent README files to use python directory](https://github.com/google/adk-samples/commit/d6a944f3b9fe33c9e7cdb8fe560c1223140c9bd9 "Update agent README files to use python directory")| May 20, 2025
[llm_auditor_architecture.png](https://github.com/google/adk-samples/blob/main/python/agents/llm-auditor/llm_auditor_architecture.png "llm_auditor_architecture.png")| [llm_auditor_architecture.png](https://github.com/google/adk-samples/blob/main/python/agents/llm-auditor/llm_auditor_architecture.png "llm_auditor_architecture.png")| [Add python top-level directory](https://github.com/google/adk-samples/commit/adf640295027be408de52734372b0f8d53e01f75 "Add python top-level directory")| May 20, 2025
[pyproject.toml](https://github.com/google/adk-samples/blob/main/python/agents/llm-auditor/pyproject.toml "pyproject.toml")| [pyproject.toml](https://github.com/google/adk-samples/blob/main/python/agents/llm-auditor/pyproject.toml "pyproject.toml")| [Update llm-auditor to ADK 1.0](https://github.com/google/adk-samples/commit/6c187b0c436f5b629a5c4cc7dcbe9b03dd8d48c1 "Update llm-auditor to ADK 1.0")| May 22, 2025
View all files
## [README.md](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#readme)
Outline
# LLM Auditor
[](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#llm-auditor)
This agent functions as an automated fact-checking layer specifically designed to evaluate and enhance the factual grounding of responses generated by Large Language Models (LLMs). Its primary role is to bolster the reliability of LLM outputs by systematically analyzing them against real-world information; it achieves this by identifying verifiable claims within the text, utilizing web search and its internal knowledge to determine their accuracy, producing a detailed report on its findings, and optionally rewriting the original response to correct any discovered inaccuracies.
## Overview
[](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#overview)
This agent evaluates and improves the factual grounding of responses generated by LLMs. Its primary purpose is to serve as an automated fact-checking layer, analyzing LLM answers against real-world information to enhance reliability.
  * Identifies and isolates specific, verifiable statements within an LLM-generated text.
  * Determines accuracy of claims using web search tools and knowledge it is trained on.
  * Produces a clear breakdown listing identified claims with their verification status.
  * Optionally rewrites original responses to correct inaccuracies based on verified findings.


This sample agent enables a user to query an LLM and the agent audits the corresponding answer by extracting claims, utilizing search tools for verification, generating an audit report, and optionally re-writing the response.
## Agent Details
[](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#agent-details)
The key features of the LLM Auditor include:
Feature | Description
---|---
**Interaction Type** | Workflow
**Complexity** | Easy
**Agent Type** | Multi Agent
**Components** | Tools: built-in Google Search
**Vertical** | Horizontal
### Agent architecture:
[](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#agent-architecture)
This diagram shows the detailed architecture of the agents and tools used to implement this workflow. [![LLM Auditor Architecture](https://github.com/google/adk-samples/raw/main/python/agents/llm-auditor/llm_auditor_architecture.png)](https://github.com/google/adk-samples/blob/main/python/agents/llm-auditor/llm_auditor_architecture.png)
## Setup and Installation
[](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#setup-and-installation)
  1. **Prerequisites**
     * Python 3.11+
     * Poetry
       * For dependency management and packaging. Please follow the instructions on the official [Poetry website](https://python-poetry.org/docs/) for installation.
```
pip install poetry
```

     * A project on Google Cloud Platform
     * Google Cloud CLI
       * For installation, please follow the instruction on the official [Google Cloud website](https://cloud.google.com/sdk/docs/install).
  2. **Installation**
```
# Clone this repository.
git clone https://github.com/google/adk-samples.git
cd adk-samples/python/agents/llm-auditor
# Install the package and dependencies.
poetry install
```

  3. **Configuration**
     * Set up Google Cloud credentials.
       * You may set the following environment variables in your shell, or in a `.env` file instead.
```
export GOOGLE_GENAI_USE_VERTEXAI=true
export GOOGLE_CLOUD_PROJECT=<your-project-id>
export GOOGLE_CLOUD_LOCATION=<your-project-location>
export GOOGLE_CLOUD_STORAGE_BUCKET=<your-storage-bucket> # Only required for deployment on Agent Engine
```

     * Authenticate your GCloud account.
```
gcloud auth application-default login
gcloud auth application-default set-quota-project $GOOGLE_CLOUD_PROJECT
```

     * If you'd prefer to run the agent locally without using Google Vertex AI or Cloud dependencies, you may set the following environment variables in your shell, or in a `.env` file instead.
```
export GOOGLE_GENAI_USE_VERTEXAI=false
export GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE
```

Refer to the [Google Gemini API Quickstart](https://ai.google.dev/gemini-api/docs/quickstart?lang=python#make-first-request) for instructions on obtaining a Google Gemini API key.


## Running the Agent
[](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#running-the-agent)
**Using`adk`**
ADK provides convenient ways to bring up agents locally and interact with them. You may talk to the agent using the CLI:
```
adk run llm_auditor
```

Or on a web interface:
```
adk web
```

The command `adk web` will start a web server on your machine and print the URL. You may open the URL, select "llm_auditor" in the top-left drop-down menu, and a chatbot interface will appear on the right. The conversation is initially blank. Here are some example requests you may ask the LLM Auditor to verify:
  * `Double check this: Earth is further away from the Sun than Mars.`
  * `Q: Why the blueberries are blue? A: Because blueberries have pigments on their skin.`


Sampled responses of these requests are shown below in the [Example Interaction](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#example-interaction) section.
**Programmatic Access**
Below is an example of interacting with the agent using Python:
```
import dotenv
dotenv.load_dotenv() # May skip if you have exported environment variables.
from google.adk.runners import InMemoryRunner
from google.genai.types import Part, UserContent
from llm_auditor.agent import root_agent
user_input = "Double check this: Earth is further away from the Sun than Mars."
runner = InMemoryRunner(agent=root_agent)
session = runner.session_service.create_session(
  app_name=runner.app_name, user_id="test_user"
)
content = UserContent(parts=[Part(text=user_input)])
for event in runner.run(
  user_id=session.user_id, session_id=session.id, new_message=content
):
  for part in event.content.parts:
    print(part.text)
```

You may also utilize `google.adk.Runner` to have fine-grained control on interaction sessions and more, or wrap the agent in a `vertexai.preview.reasoning_engines.AdkApp`.
### Example Interaction
[](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#example-interaction)
Below is an example interaction with the LLM Auditor. Note that the exact output of the agent may be different every time.
```
user: Double check this: Earth is further away from the Sun than Mars.
[critic_agent]: Okay, I will double-check the statement: "Earth is further away
from the Sun than Mars."
**Step 1: Identify the CLAIMS**
The answer contains one claim:
* CLAIM 1: Earth is further away from the Sun than Mars.
**Step 2: Verify each CLAIM**
* CLAIM 1: Earth is further away from the Sun than Mars.
  * Context: This is a direct statement of fact about the relative distances
   of Earth and Mars from the Sun.
  * External Sources: I will use Google Search to check the average distances
   of Earth and Mars from the Sun.
  * Verdict: **Inaccurate**.
  * Justification: According to the search results, the average distance of
   Earth from the Sun is approximately 150 million kilometers [2, 3, 6, 9],
   while the average distance of Mars from the Sun is approximately 228
   million kilometers [1, 4, 5, 8, 10]. Therefore, Mars is further away from
   the Sun than Earth, contradicting the claim.
**Step 3: Provide an overall assessment**
  * OVERALL VERDICT: Inaccurate
  * OVERALL JUSTIFICATION: The single claim made in the answer is demonstrably
   false based on widely available astronomical data. Therefore, the answer
   as a whole is incorrect.
Here's a summary of my verification results:
* Claim: Earth is further away from the Sun than Mars.
  * Part in answer text: "Earth is further away from the Sun than Mars."
  * Verdict: Inaccurate
  * Justification: The average distance of Earth from the Sun is about 150
   million kilometers, while the average distance of Mars from the Sun is
   about 228 million kilometers. Thus, Mars is farther from the sun than the
   Earth.
Reference:
<omitted for clarity>
[reviser_agent]: Mars is further away from the Sun than Earth.

```

```
user: Q: Why the blueberries are blue? A: Because blueberries have pigments on
their skin.
[critic_agent]: Okay, I will analyze the answer to the question "Why the
blueberries are blue?" to verify its accuracy and completeness.
**Step 1: Identify the CLAIMS**
I've identified the following CLAIM in the answer:
*  CLAIM 1: Blueberries are blue because they have pigments on their skin.
**Step 2: Verify each CLAIM**
Now, I will verify the identified claim.
*  Consider the Context: The question asks for the reason behind the blue color
  of blueberries.
*  Consult External Sources: I'll use Google Search to find information about
  the pigments responsible for the blue color of blueberries.
*  Determine the VERDICT:
  *  CLAIM 1: Blueberries are blue because they have pigments on their skin.
    The initial answer is partially correct but incomplete. While
    blueberries do have pigments, specifically anthocyanins, in their skin
    [2, 4, 6, 8, 9], the blue color we perceive is primarily due to a waxy
    coating on the surface of the fruit that scatters blue light [1, 2, 3,
    5, 10, 11]. The pigment underneath is actually dark red [1, 3, 5, 10].
*  VERDICT: Inaccurate. The answer is not entirely wrong, as blueberries do
  contain pigments in their skin. However, it's misleading because it
  attributes the blue color solely to pigments, neglecting the crucial role of
  the waxy coating and its light-scattering properties.
**Step 3: Provide an overall assessment**
*  OVERALL VERDICT: Inaccurate
*  OVERALL JUSTIFICATION: The provided answer, while mentioning pigments, fails
  to explain the primary reason for the blue color of blueberries which is the
  waxy coating that scatters blue light. Therefore, the answer is misleading
  and inaccurate.
Reference:
<omitted for clarity>
[reviser_agent]: Blueberries are blue due to a waxy coating on their skin that
scatters blue light. They also have pigments on their skin.

```

## Running Tests
[](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#running-tests)
For running tests and evaluation, install the extra dependencies:
```
poetry install --with dev
```

Then the tests and evaluation can be run from the `llm-auditor` directory using the `pytest` module:
```
python3 -m pytest tests
python3 -m pytest eval
```

`tests` runs the agent on a sample request, and makes sure that every component is functional. `eval` is a demonstration of how to evaluate the agent, using the `AgentEvaluator` in ADK. It sends a couple requests to the agent and expects that the agent's responses match a pre-defined response reasonably well.
## Deployment
[](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#deployment)
The LLM Auditor can be deployed to Vertex AI Agent Engine using the following commands:
```
poetry install --with deployment
python3 deployment/deploy.py --create
```

When the deployment finishes, it will print a line like this:
```
Created remote agent: projects/<PROJECT_NUMBER>/locations/<PROJECT_LOCATION>/reasoningEngines/<AGENT_ENGINE_ID>

```

If you forgot the AGENT_ENGINE_ID, you can list existing agents using:
```
python3 deployment/deploy.py --list
```

The output will be like:
```
All remote agents:
123456789 ("llm_auditor")
- Create time: 2025-04-09 08:22:36.179879+00:00
- Update time: 2025-04-09 08:25:42.734584+00:00

```

You may interact with the deployed agent programmatically in Python:
```
import dotenv
dotenv.load_dotenv() # May skip if you have exported environment variables.
from vertexai import agent_engines
agent_engine_id = "AGENT_ENGINE_ID"
user_input = "Double check this: Earth is further away from the Sun than Mars."
agent_engine = agent_engines.get(agent_engine_id)
session = agent_engine.create_session(user_id="new_user")
for event in agent_engine.stream_query(
  user_id=session["user_id"], session_id=session["id"], message=user_input
):
  for part in event["content"]["parts"]:
    print(part["text"])
```

To delete the deployed agent, you may run the following command:
```
python3 deployment/deploy.py --delete --resource_id=${AGENT_ENGINE_ID}
```

## Customization
[](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#customization)
The LLM Auditor can be customized to better suit your requirements. For example:
  1. **Substitute the Retrieval Mechanism:** Replace the `critic` sub-agent's default `built_in_google_search` tool with an alternative retrieval tool tailored to your data sources.
  2. **Customize Agent Instructions:** Modify the prompts guiding the `critic` and `reviser` sub-agents. This allows you to direct their focus (e.g., checking against specific compliance rules, ensuring a certain writing style) or refine the format of their feedback and revisions.
  3. **Implement Iterative Processing:** Configure the LLM Auditor to operate iteratively. Instead of a single pass, the response can be repeatedly evaluated and rewritten by the agents until predefined quality thresholds are achieved.


## Disclaimer
[](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor#disclaimer)
This agent sample is provided for illustrative purposes only and is not intended for production use. It serves as a basic example of an agent and a foundational starting point for individuals or teams to develop their own agents.
This sample has not been rigorously tested, may contain bugs or limitations, and does not include features or optimizations typically required for a production environment (e.g., robust error handling, security measures, scalability, performance considerations, comprehensive logging, or advanced configuration options).
Users are solely responsible for any further development, testing, security hardening, and deployment of agents based on this sample. We recommend thorough review, testing, and the implementation of appropriate safeguards before using any derived agent in a live or critical system.
You canât perform that action at this time.
